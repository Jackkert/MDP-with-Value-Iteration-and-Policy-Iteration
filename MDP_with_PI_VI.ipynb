{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements value iteration and policy iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Decision Process - MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MDP, there is an agent. The agent choose an action $a_{t}$ at time $t$ and as a consequence, the environment changes.\n",
    "Here the evniorment is world around the agent. After taking the action, the environment state changes to $s_{t+1}$.\n",
    "A reward might be emitted associated with what just happened and then this process repeats. ![](nb_images/mdp.png)\n",
    "\n",
    "So, there is a feedback cycle in that the next action you take, the next decision you make is in a situation that's the consiquence of what you did before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import gymnasium.spaces as spaces\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← ↓ → ↑\n"
     ]
    }
   ],
   "source": [
    "# action mapping for display the final result\n",
    "action_mapping = {\n",
    "    3: '\\u2191', # UP\n",
    "    2: '\\u2192', # RIGHT\n",
    "    1: '\\u2193', # DOWN\n",
    "    0: '\\u2190' # LEFT\n",
    "}\n",
    "print(' '.join([action_mapping[i] for i in range(4)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup GYM Env for playing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that will take a GYM environment and plays number of games according to given policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episodes(environment, n_episodes, policy, random = False, categorial = False):\n",
    "    \"\"\"\n",
    "    This fucntion plays the given number of episodes given by following a policy or sample randomly from action_space.\n",
    "    \n",
    "    Parameters:\n",
    "        environment: openAI GYM object\n",
    "        n_episodes: number of episodes to run\n",
    "        policy: Policy to follow while playing an episode\n",
    "        random: Flag for taking random actions. if True no policy would be followed and action will be taken randomly\n",
    "        \n",
    "    Return:\n",
    "        wins: Total number of wins playing n_episodes\n",
    "        total_reward: Total reward of n_episodes\n",
    "        avg_reward: Average reward of n_episodes\n",
    "    \n",
    "    \"\"\"\n",
    "    # intialize wins and total reward\n",
    "    wins = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    # loop over number of episodes to play\n",
    "    for episode in range(n_episodes):\n",
    "        \n",
    "        # flag to check if the game is finished\n",
    "        terminated = False\n",
    "        \n",
    "        # reset the environment every time when playing a new episode\n",
    "        state = environment.reset()[0]\n",
    "\n",
    "        while not terminated:\n",
    "            \n",
    "            # check if the random flag is not true then follow the given policy other wise take random action\n",
    "            if random:\n",
    "                action = environment.action_space.sample()\n",
    "            else:\n",
    "                if categorial:\n",
    "                    action = np.random.choice(len(policy[state]), p=policy[state])\n",
    "                else:\n",
    "                    action = policy[state] \n",
    "\n",
    "            # take the next step\n",
    "            next_state, reward,  terminated, info = environment.step(action)[:-1]\n",
    "            \n",
    "            environment.render()\n",
    "            \n",
    "            # accumalate total reward\n",
    "            total_reward += reward\n",
    "            \n",
    "            # change the state\n",
    "            state = next_state\n",
    "            \n",
    "            # if game is over with positive reward then add 1.0 in wins\n",
    "            if terminated and reward == 1.0:\n",
    "                wins += 1\n",
    "                \n",
    "    # calculate average reward\n",
    "    average_reward = total_reward / n_episodes\n",
    "    \n",
    "    return wins, total_reward, average_reward\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Solve for Value Iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](nb_images/value_iter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_step_lookahead(env, state, V , discount_factor = 0.99):\n",
    "    \"\"\"\n",
    "    Helper function to  calculate state-value function\n",
    "    \n",
    "    Arguments:\n",
    "        env: openAI GYM environment object\n",
    "        state: state to consider\n",
    "        V: Estimated Value for each state. Vector of length nS\n",
    "        discount_factor: MDP discount factor\n",
    "        \n",
    "    Return:\n",
    "        action_values: Expected value of each action in a state. Vector of length nA\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize vector of action values\n",
    "    action_values = np.zeros(env.action_space.n)\n",
    "    \n",
    "    # loop over the actions we can take in an environment \n",
    "    for action in range(env.action_space.n):\n",
    "        # loop over the P_sa distribution.\n",
    "        for probablity, next_state, reward, info in env.P[state][action]:\n",
    "             #if we are in state s and take action a. then sum over all the possible states we can land into.\n",
    "            action_values[action] += probablity * (reward + (discount_factor * V[next_state]))\n",
    "            \n",
    "    return action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(env, policy, V, discount_factor):\n",
    "    \n",
    "    \"\"\"\n",
    "    Helper function to update a given policy based on given value function.\n",
    "    \n",
    "    Arguments:\n",
    "        env: openAI GYM environment object.\n",
    "        policy: policy to update.\n",
    "        V: Estimated Value for each state. Vector of length nS.\n",
    "        discount_factor: MDP discount factor.\n",
    "    Return:\n",
    "        policy: Updated policy based on the given state-Value function 'V'.\n",
    "    \"\"\"\n",
    "    \n",
    "    for state in range(env.observation_space.n):\n",
    "        # for a given state compute state-action value.\n",
    "        action_values = one_step_lookahead(env, state, V, discount_factor)\n",
    "        \n",
    "        # choose the action which maximizez the state-action value.\n",
    "        policy[state] =  np.argmax(action_values)\n",
    "        \n",
    "    return policy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, discount_factor = 0.999, max_iteration = 1000):\n",
    "    \"\"\"\n",
    "    Algorithm to solve MPD.\n",
    "    \n",
    "    Arguments:\n",
    "        env: openAI GYM environment object.\n",
    "        discount_factor: MDP discount factor.\n",
    "        max_iteration: Maximum No.  of iterations to run.\n",
    "        \n",
    "    Return:\n",
    "        V: Optimal state-Value function. Vector of lenth nS.\n",
    "        optimal_policy: Optimal policy. Vector of length nS.\n",
    "    \n",
    "    \"\"\"\n",
    "    # intialize value fucntion\n",
    "    V = np.zeros(env.observation_space.n)\n",
    "    \n",
    "    # iterate over max_iterations\n",
    "    for i in range(max_iteration):\n",
    "        \n",
    "        #  keep track of change with previous value function\n",
    "        prev_v = np.copy(V) \n",
    "    \n",
    "        # loop over all states\n",
    "        for state in range(env.observation_space.n):\n",
    "            \n",
    "            # Asynchronously update the state-action value\n",
    "            #action_values = one_step_lookahead(env, state, V, discount_factor)\n",
    "            \n",
    "            # Synchronously update the state-action value\n",
    "            action_values = one_step_lookahead(env, state, prev_v, discount_factor)\n",
    "            \n",
    "            # select best action to perform based on highest state-action value\n",
    "            best_action_value = np.max(action_values)\n",
    "            \n",
    "            # update the current state-value fucntion\n",
    "            V[state] =  best_action_value\n",
    "            \n",
    "        # if policy not changed over 10 iterations it converged.\n",
    "        if i % 10 == 0:\n",
    "            # if values of 'V' not changing after one iteration\n",
    "            if (np.all(np.isclose(V, prev_v))):\n",
    "                print('Value converged at iteration %d' %(i+1))\n",
    "                break\n",
    "\n",
    "    # intialize optimal policy\n",
    "    optimal_policy = np.zeros(env.observation_space.n, dtype = 'int8')\n",
    "    \n",
    "    # update the optimal polciy according to optimal value function 'V'\n",
    "    optimal_policy = update_policy(env, optimal_policy, V, discount_factor)\n",
    "    \n",
    "    return V, optimal_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Algorithim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value converged at iteration 341\n",
      "Time to converge:  4.47e+02 ms\n",
      "Optimal Value function: \n",
      "[[0.78538826 0.77836049 0.77368481 0.7713498 ]\n",
      " [0.78775777 0.         0.50562724 0.        ]\n",
      " [0.79250312 0.79963699 0.74472318 0.        ]\n",
      " [0.         0.86409247 0.93114742 0.        ]]\n",
      "Final Policy: \n",
      "[0 3 3 3 0 0 0 0 3 1 0 0 0 2 1 0]\n",
      "← ↑ ↑ ↑ ← ← ← ← ↑ ↓ ← ← ← → ↓ ←\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackkert/anaconda3/envs/ics/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.P to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.P` for environment variables or `env.get_wrapper_attr('P')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "environment = gym.make('FrozenLake-v1')\n",
    "tic = time.time()\n",
    "opt_V, opt_Policy = value_iteration(environment.env, max_iteration = 1000)\n",
    "toc = time.time()\n",
    "elapsed_time = (toc - tic) * 1000\n",
    "print (f\"Time to converge: {elapsed_time: 0.3} ms\")\n",
    "print('Optimal Value function: ')\n",
    "print(opt_V.reshape((4, 4)))\n",
    "print('Final Policy: ')\n",
    "print(opt_Policy)\n",
    "print(' '.join([action_mapping[int(action)] for action in opt_Policy]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackkert/anaconda3/envs/ics/lib/python3.11/site-packages/gymnasium/envs/toy_text/frozen_lake.py:328: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"FrozenLake-v1\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "n_episode = 10\n",
    "wins, total_reward, avg_reward = play_episodes(environment, n_episode, opt_Policy, random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total wins with value iteration: 9\n",
      "Average rewards with value iteration: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(f'Total wins with value iteration: {wins}')\n",
    "print(f\"Average rewards with value iteration: {avg_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Solve for Policy Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_eval(env, policy, Q, discount_factor):\n",
    "    \"\"\"\n",
    "    Helper function to evaluate a policy.\n",
    "    \n",
    "    Arguments:\n",
    "        env: openAI GYM environment object.\n",
    "        policy: policy to evaluate.\n",
    "        Q: Estimated Value for each state-action pair. Table of shape N x A\n",
    "        discount_factor: MDP discount factor.\n",
    "    Return:\n",
    "        policy_value: Estimated value of each state-action pair following a given policy and state-action value 'Q'. \n",
    "        \n",
    "    \"\"\"\n",
    "    policy_value = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    for state in range(env.observation_space.n):\n",
    "        for action, action_prob in enumerate(policy[state]): # evaluate policy value over all actions\n",
    "            for probablity, next_state, reward, info in env.P[state][action]:\n",
    "                policy_value[state][action] += probablity * (reward + (discount_factor * np.max(Q[next_state])))\n",
    "    \n",
    "    return policy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_lookahead_categorial(env, state, Q , discount_factor = 0.99):\n",
    "    \"\"\"\n",
    "    Helper function to  calculate state-value function\n",
    "    \n",
    "    Arguments:\n",
    "        env: openAI GYM environment object\n",
    "        state: state to consider\n",
    "        Q: Estimated Value for each state-action pair. Table of shape N x A\n",
    "        discount_factor: MDP discount factor\n",
    "        \n",
    "    Return:\n",
    "        action_values: Expected value of each action in a state. Vector of length nA\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize vector of action values\n",
    "    action_values = np.zeros(env.action_space.n) \n",
    "    # loop over the actions we can take in an environment \n",
    "    for action in range(env.action_space.n):\n",
    "        # loop over the P_sa distribution.\n",
    "        for probablity, next_state, reward, info in env.P[state][action]:\n",
    "             #if we are in state s and take action a. then sum over all the possible states we can land into.\n",
    "            action_values[action] += probablity * (reward + (discount_factor * np.max(Q[next_state])))\n",
    "            \n",
    "    return action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_regularized_softmax(policy, temperature, Q_value):\n",
    "    \"\"\"\n",
    "    Helper function for the policy-regularized softmax function.\n",
    "\n",
    "    Arguments:\n",
    "        policy: current evaluated policy\n",
    "        temperature: temperature hyperparameter \n",
    "        Q_value: current Q value function\n",
    "    Return:\n",
    "        action_dist: Improved action probability distribution for the new policy.\n",
    "    \"\"\"\n",
    "    # convert to torch tensor\n",
    "    policy = torch.from_numpy(policy)\n",
    "    Q_value = torch.from_numpy(Q_value)\n",
    "    action_dist = torch.nn.functional.softmax(torch.log(policy) + temperature * Q_value)\n",
    "    return action_dist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update policy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy_categorial(env, policy, Q, discount_factor, temperature, improvement_operator = \"argmax\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Helper function to update a given policy based on given value function.\n",
    "    \n",
    "    Arguments:\n",
    "        env: openAI GYM environment object.\n",
    "        policy: categorial policy to update.\n",
    "        Q: Estimated Value for each state-action pair. Table of shape N x S.\n",
    "        discount_factor: MDP discount factor.\n",
    "    Return:\n",
    "        policy: Updated policy based on the given state-action value function 'Q'.\n",
    "    \"\"\"\n",
    "    if improvement_operator == \"None\":\n",
    "        return policy\n",
    "    \n",
    "    for state in range(env.observation_space.n):\n",
    "        # for a given state compute state-action value.\n",
    "        action_values = one_step_lookahead_categorial(env, state, Q, discount_factor)\n",
    "        # choose the action which maximizez the state-action value.\n",
    "        if improvement_operator == \"argmax\":\n",
    "            best_action = np.argmax(action_values)\n",
    "            one_hot_policy = np.zeros(env.action_space.n)\n",
    "            one_hot_policy[best_action] = 1\n",
    "            policy[state] = one_hot_policy\n",
    "        elif improvement_operator == \"policy-regularized_softmax\":\n",
    "            policy[state] = policy_regularized_softmax(policy[state], temperature, action_values)\n",
    "        \n",
    "    return policy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(env, improvement_operator = \"argmax\", value_improvement_operator = \"argmax\", discount_factor = 0.999, max_iteration = 1000):\n",
    "    \"\"\"\n",
    "    Algorithm to solve MPD.\n",
    "    \n",
    "    Arguments:\n",
    "        env: openAI GYM environment object.\n",
    "        discount_factor: MDP discount factor.\n",
    "        max_iteration: Maximum No.  of iterations to run.\n",
    "        \n",
    "    Return:\n",
    "        Q: Optimal state-action value function. Table of N x A\n",
    "        new_policy: Optimal policy. Table of N x A\n",
    "    \n",
    "    \"\"\"\n",
    "    # intialize the state-Value function\n",
    "    Q = np.zeros((env.observation_space.n,env.action_space.n))\n",
    "    Q_copied = np.zeros((env.observation_space.n,env.action_space.n))\n",
    "    # intialize a random implicit categorial policy\n",
    "    random_actions = np.random.randint(0, 1000, (env.observation_space.n, env.action_space.n))\n",
    "    policy = random_actions/random_actions.sum(axis = 1, keepdims = True)\n",
    "\n",
    "\n",
    "    policy_prev = np.copy(policy)\n",
    "    temperature = 1.0\n",
    "    for i in range(max_iteration):\n",
    "        # copy the policy\n",
    "        copied_policy = np.copy(policy) # could also use policy_prev but for readability now this is fine.\n",
    "        # improve copied policy with second improvement operator\n",
    "        copied_policy = update_policy_categorial(env, copied_policy, Q_copied, discount_factor, temperature, improvement_operator=value_improvement_operator)\n",
    "        # Evaluate copied policy \n",
    "        Q_copied = policy_eval(env, copied_policy, Q_copied, discount_factor)\n",
    "        # evaluate given policy\n",
    "        Q = policy_eval(env, policy, Q, discount_factor)\n",
    "        # improve the main policy with Q_copied\n",
    "        policy = update_policy_categorial(env, policy, Q_copied, discount_factor, temperature, improvement_operator=improvement_operator)\n",
    "        \n",
    "        # if policy not changed over 10 iterations it converged.\n",
    "        if i % 10 == 0:\n",
    "            if (np.all(np.equal(policy, policy_prev))):\n",
    "                print('policy converged at iteration %d' %(i+1))\n",
    "                break\n",
    "            policy_prev = np.copy(policy)\n",
    "            \n",
    "\n",
    "            \n",
    "    return Q, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50809/1363818680.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  action_dist = torch.nn.functional.softmax(torch.log(policy) + temperature * Q_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to converge:  4.92e+04 ms\n",
      "Optimal Value function: \n",
      "[[0.78553326 0.78320919 0.78320919 0.78242366]\n",
      " [0.52084109 0.51929558 0.51697151 0.77855409]\n",
      " [0.68537991 0.68460832 0.68306281 0.77391292]\n",
      " [0.51465441 0.51465441 0.51388281 0.77159582]\n",
      " [0.78789222 0.52630964 0.52552411 0.52395068]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.50573092 0.24801792 0.50573092 0.257713  ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.52630964 0.53024911 0.52867568 0.79261722]\n",
      " [0.55170453 0.79972245 0.53578092 0.51195945]\n",
      " [0.74479855 0.57639015 0.47849097 0.43471597]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.55407058 0.59784558 0.86415315 0.57639015]\n",
      " [0.84586349 0.93117891 0.89143383 0.86911425]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Final Policy: \n",
      "[[1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   1.  ]\n",
      " [0.   0.   0.   1.  ]\n",
      " [0.   0.   0.   1.  ]\n",
      " [1.   0.   0.   0.  ]\n",
      " [0.25 0.26 0.48 0.  ]\n",
      " [0.58 0.   0.42 0.  ]\n",
      " [0.35 0.2  0.17 0.27]\n",
      " [0.   0.   0.   1.  ]\n",
      " [0.   1.   0.   0.  ]\n",
      " [1.   0.   0.   0.  ]\n",
      " [0.31 0.19 0.38 0.12]\n",
      " [0.09 0.34 0.31 0.27]\n",
      " [0.   0.   1.   0.  ]\n",
      " [0.   1.   0.   0.  ]\n",
      " [0.48 0.32 0.01 0.19]]\n",
      "Most likely actions taken by policy: \n",
      "← ↑ ↑ ↑ ← → ← ← ↑ ↓ ← → ↓ → ↓ ←\n"
     ]
    }
   ],
   "source": [
    "environment2 = gym.make('FrozenLake-v1') #, render_mode = \"human\")\n",
    "tic = time.time()\n",
    "# options for improvement operator: \"argmax\", \"policy-regularized_softmax\" or \"None\"\n",
    "opt_V2, opt_policy2 = policy_iteration(environment2.env, improvement_operator=\"policy-regularized_softmax\", value_improvement_operator = \"policy-regularized_softmax\", discount_factor = 0.999, max_iteration = 10000)\n",
    "toc = time.time()\n",
    "elapsed_time = (toc - tic) * 1000\n",
    "print (f\"Time to converge: {elapsed_time: 0.3} ms\")\n",
    "print('Optimal Value function: ')\n",
    "print(opt_V2.reshape((environment2.observation_space.n, environment2.action_space.n)))\n",
    "print('Final Policy: ')\n",
    "print(np.round(opt_policy2,2))\n",
    "# Display the most likely policy in discrete action\n",
    "print(\"Most likely actions taken by policy: \")\n",
    "print(' '.join([action_mapping[(np.argmax(action))] for action in opt_policy2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episode = 10\n",
    "wins, total_reward, avg_reward = play_episodes(environment2, n_episode, opt_policy2, random = False, categorial = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total wins with Policy iteration: 9\n",
      "Average rewards with Policy iteration: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(f'Total wins with Policy iteration: {wins}')\n",
    "print(f\"Average rewards with Policy iteration: {avg_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy converged at iteration 31\n",
      "Time to converge argmax-none:  90.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50809/1363818680.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  action_dist = torch.nn.functional.softmax(torch.log(policy) + temperature * Q_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to converge softmax-argmax:  4.6e+04 ms\n",
      "Time to converge softmax-softmax:  5.25e+04 ms\n"
     ]
    }
   ],
   "source": [
    "environment_comparison = gym.make('FrozenLake-v1') #, render_mode = \"human\")\n",
    "\n",
    "tic = time.time()\n",
    "# options for improvement operator: \"argmax\", \"policy-regularized_softmax\" or \"None\"\n",
    "opt_Q_argmax_one, opt_policy_argmax_none = policy_iteration(environment_comparison.env, improvement_operator=\"argmax\", value_improvement_operator = \"None\", discount_factor = 0.999, max_iteration = 10000)\n",
    "toc = time.time()\n",
    "argmax_none_elapsed_time = (toc - tic) * 1000\n",
    "print(f\"Time to converge argmax-none: {argmax_none_elapsed_time: 0.3} ms\")\n",
    "\n",
    "tic = time.time()\n",
    "# options for improvement operator: \"argmax\", \"policy-regularized_softmax\" or \"None\"\n",
    "opt_Q_softmax_argmax, opt_policy_softmax_argmax = policy_iteration(environment_comparison.env, improvement_operator=\"policy-regularized_softmax\", value_improvement_operator = \"argmax\", discount_factor = 0.999, max_iteration = 10000)\n",
    "toc = time.time()\n",
    "softmax_argmax_elapsed_time = (toc - tic) * 1000\n",
    "print(f\"Time to converge softmax-argmax: {softmax_argmax_elapsed_time: 0.3} ms\")\n",
    "\n",
    "tic = time.time()\n",
    "# options for improvement operator: \"argmax\", \"policy-regularized_softmax\" or \"None\"\n",
    "opt_Q_softmax_softmax, opt_policy_softmax_softmax = policy_iteration(environment_comparison.env, improvement_operator=\"policy-regularized_softmax\", value_improvement_operator = \"policy-regularized_softmax\", discount_factor = 0.999, max_iteration = 10000)\n",
    "toc = time.time()\n",
    "softmax_softmax_elapsed_time = (toc - tic) * 1000\n",
    "print(f\"Time to converge softmax-softmax: {softmax_softmax_elapsed_time: 0.3} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_episodes = 100\n",
    "policies = [opt_policy_argmax_none, opt_policy_softmax_argmax, opt_policy_softmax_softmax]\n",
    "elapsed_times = [argmax_none_elapsed_time, softmax_argmax_elapsed_time, softmax_softmax_elapsed_time]\n",
    "\n",
    "wins_per_policy = []\n",
    "total_rewards_per_policy = []\n",
    "avg_rewards_per_policy = []\n",
    "\n",
    "for policy in policies:\n",
    "    n_wins, total_reward, avg_reward = play_episodes(environment_comparison, comparison_episodes, policy, random = False, categorial = True)\n",
    "    wins_per_policy.append(n_wins)\n",
    "    total_rewards_per_policy.append(total_reward)\n",
    "    avg_rewards_per_policy.append(avg_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(elapsed_times))\n",
    "width = 0.5  # Width of the bars\n",
    "\n",
    "# Creating the bar plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "bar = ax[0].bar(\"Argmax-None\", elapsed_times[0], width)\n",
    "bar = ax[0].bar(\"Softmax-None\", elapsed_times[1], width)\n",
    "bar = ax[0].bar(\"Softmax-Softmax\", elapsed_times[2], width)\n",
    "\n",
    "# Adding labels, title, and ticksax.set_xlabel('Elapsed Time')\n",
    "ax[0].set_ylabel('Time in ms')\n",
    "ax[0].set_title('Time to converge')\n",
    "ax[0].set_xticks(x)\n",
    "ax[0].legend()\n",
    "\n",
    "bar = ax[1].bar(\"Argmax-None\", wins_per_policy[0], width)\n",
    "bar = ax[1].bar(\"Softmax-None\", wins_per_policy[1], width)\n",
    "bar = ax[1].bar(\"Softmax-Softmax\", wins_per_policy[2], width)\n",
    "\n",
    "ax[1].set_ylabel('Number of wins')\n",
    "ax[1].set_title('Number of wins out of 100')\n",
    "ax[1].set_xticks(x)\n",
    "ax[1].legend()\n",
    "# Showing the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
